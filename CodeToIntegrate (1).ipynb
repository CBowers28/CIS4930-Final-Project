{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c5d0d9-f0af-4f49-a7e2-edcef7d05fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_df():\n",
    "    df = pd.read_csv(\"MIT-BIH Arrhythmia Database.csv\")\n",
    "    if 'record' in df.columns:\n",
    "        df = df.drop(columns=['record'])\n",
    "    df = df[df['type'] != 'Q']\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['type'] = label_encoder.fit_transform(df['type'])\n",
    "    return df\n",
    "\n",
    "def initialize_data(df):\n",
    "    X = df.drop(columns=['type'])\n",
    "    y = df['type']\n",
    "    return X, y\n",
    "\n",
    "def clean_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform both training and test data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Apply SMOTE to the training data, to balance the classes\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    return X_train_resampled, y_train_resampled, X_test_scaled, y_test\n",
    "\n",
    "def get_accuracy(y_pred, y_test):\n",
    "    accuracy = 1 - np.sum(np.abs(y_pred - y_test)) / np.shape(y_pred)[0]\n",
    "    return accuracy\n",
    "\n",
    "def test_prediction(df):\n",
    "    #Create Weak Learner\n",
    "    rf_model = sklearn.ensemble.RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "    X, y = initialize_data(df)\n",
    "    X_train, y_train, X_test, y_test = clean_data(X, y)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    return get_accuracy(y_pred, y_test)\n",
    "\n",
    "def print_statistics(y_pred, y_test):\n",
    "    #Visualize the Confusion Matrix\n",
    "    print(\"The Confusion Matrix of the Model is:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    #Calculate the Accuracy\n",
    "    accuracy = get_accuracy(y_pred, y_test)\n",
    "    print(\"The Accuracy of the Model is:\", accuracy, \"/ 1.0\")\n",
    "    #Calculate the Precision, Recall, and F1 Score\n",
    "    prf = precision_recall_fscore_support(y_pred, y_test, average='weighted')\n",
    "    print(\"The Precision of the Model is:\", prf[0], \"/ 1.0\")\n",
    "    print(\"The Recall of the Model is:\", prf[1], \"/ 1.0\")\n",
    "    print(\"The F1 Score is:\", prf[2])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f666a-17f6-4599-9e4b-471054698607",
   "metadata": {},
   "source": [
    "Feature Selection: Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf19f9-c401-4613-8b8a-13b160ca6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Method: Calculate Pearson Coefficient\n",
    "df = initialize_df()\n",
    "res = list()\n",
    "for c in df.columns:\n",
    "    res.append((c, stats.pearsonr(df[c], df[\"type\"]).statistic))\n",
    "\n",
    "#Drop Uncorrelated Features\n",
    "print(\"Uncorrelated Features:\")\n",
    "for p in res:\n",
    "    r = p[1]\n",
    "    if np.abs(r) < 0.1: #All features have a coefficient < 0.5, so we lower the minimum to remove them to < 0.1\n",
    "        print(p[0], p[1])\n",
    "        df = df.drop(columns=[p[0]])\n",
    "\n",
    "#Find Accuracy\n",
    "y_pred_filter = test_prediction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27f890-5706-4bea-a2ae-5aaf36dbcfd6",
   "metadata": {},
   "source": [
    "Feature Selection: Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f811591-43f6-4004-96b4-c0a6b4996c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Method: Start with Full Set of Features & Begin Removing Features Based on which increases accuracy the most\n",
    "df = initialize_df()\n",
    "cond = True\n",
    "while cond == True:\n",
    "    curr = 'type'\n",
    "    wrap_accuracy = test_prediction(df)\n",
    "    print(\"Initial Performance:\", wrap_accuracy)\n",
    "    max_ = wrap_accuracy\n",
    "    for c in df.drop(columns=['type']).columns:\n",
    "        pred = test_prediction(df.drop(columns=[c]))\n",
    "        print(\"Remove\", c, \"Performance\", pred)\n",
    "        if pred > max_:\n",
    "            curr = c\n",
    "            max_ = pred\n",
    "    #max = y_pred_wrap\n",
    "    #for i in range(len(predictions)):\n",
    "        #if predictions[i][\n",
    "    if curr == 'type':\n",
    "        print(\"Current Set Best Performance\")\n",
    "        cond = False\n",
    "    else:\n",
    "        print(\"Dropped Feature:\", curr)\n",
    "        df = df.drop(columns=[curr])\n",
    "\n",
    "#Find Accuracy\n",
    "y_pred_wrap = test_prediction(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
