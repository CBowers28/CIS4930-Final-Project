{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14af09-62a3-46f3-9f89-1ce9bdf51f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:43:15.948142Z",
     "start_time": "2025-04-20T17:43:15.398113Z"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sadmansakib7/ecg-arrhythmia-classification-dataset\")\n",
    "\n",
    "file_name = 'MIT-BIH Arrhythmia Database.csv'\n",
    "full_path = os.path.join(path, file_name)\n",
    "\n",
    "print(\"Full path to file:\", full_path)\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(full_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e40c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:43:42.503407Z",
     "start_time": "2025-04-20T17:43:15.974509Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# This code block is for the data exploration and visualization\n",
    "\n",
    "# N (Normal):\n",
    "# Description: Represents normal heartbeats. These are the most common and indicate a regular, healthy heartbeat pattern.\n",
    "# Count: 90,083 instances in your dataset, indicating that normal heartbeats are the majority class.\n",
    "# VEB (Ventricular Ectopic Beat):\n",
    "# Description: These are premature heartbeats originating from the ventricles.\n",
    "# Count: 7,009 instances, making it a minority class compared to normal beats.\n",
    "# SVEB (Supraventricular Ectopic Beat):\n",
    "# Description: These are premature heartbeats originating above the ventricles, often in the atria.\n",
    "# Count: 2,779 instances, another minority class.\n",
    "# F (Fusion Beat):\n",
    "# Description: Fusion beats occur when a normal heartbeat and an ectopic beat occur at the same time\n",
    "# Count: 803 instances, indicating it's a relatively rare occurrence in your dataset.\n",
    "# Q (Unknown/Unclassified):\n",
    "# Description: This category might represent beats that couldn't be classified into the other categories\n",
    "# Count: 15 instances, making it the rarest class in your dataset, should be removed\n",
    "\n",
    "# ------------------\n",
    "# Basic Data Visualization\n",
    "# ------------------\n",
    "\n",
    "# Bar chart of class distribution\n",
    "df['type'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Heartbeat Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Data exploration\n",
    "print(f'Dataset Shape: {df.shape}\\n')\n",
    "print(df.head(5))\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "# Columns in dataset:\n",
    "print(df.columns)\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# ------------------\n",
    "# Univariate Analysis: Distribution of Each Feature\n",
    "# ------------------\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if col != 'type':\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df[col], kde=True, bins=30)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# from the visualization, we can see that there are some classes with very few samples, and classes that don't do anything\n",
    "if 'record' in df.columns:\n",
    "    df = df.drop(columns=['record'])\n",
    "\n",
    "# drop type ==  Q, not enough samples to form worthwhile predictions\n",
    "df = df[df['type'] != 'Q']\n",
    "\n",
    "# Encode the 'type' column,  because the classes are not ordinal\n",
    "label_encoder = LabelEncoder()\n",
    "df['type'] = label_encoder.fit_transform(df['type'])\n",
    "df = df.dropna()\n",
    "\n",
    "# Print the mapping of classes to encoded values\n",
    "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
    "\n",
    "# ------------------\n",
    "# Correlation Heatmap After Dropping Features\n",
    "# ------------------\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation (After Dropping Features)')\n",
    "plt.show()\n",
    "\n",
    "# ==========================\n",
    "# Multivariate Analysis\n",
    "# ==========================\n",
    "\n",
    "# 1. Pairplot for selected important features\n",
    "\n",
    "selected_features = ['0_qt_interval', '0_pq_interval', '0_qrs_interval', 'type']\n",
    "sns.pairplot(df[selected_features], hue='type')\n",
    "plt.suptitle('Pairplot of Selected Features', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 2. Scatter plot between two key features\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='0_pre-RR',\n",
    "    y='0_post-RR',\n",
    "    color='cyan',    # Pick a single color for all dots\n",
    "    alpha=0.7,\n",
    "    edgecolor=None\n",
    ")\n",
    "plt.title('0_pre-RR vs 0_post-RR (No Legend)', fontsize=16)\n",
    "plt.xlabel('0_pre-RR Interval (ms)', fontsize=14)\n",
    "plt.ylabel('0_post-RR Interval (ms)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Disable the legend here\n",
    "plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()\n",
    "# 3. Boxplots to examine feature distributions across types\n",
    "for col in ['0_qt_interval', '0_pq_interval', '0_qrs_interval']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(x='type', y=col, data=df)\n",
    "    plt.title(f'{col} by Type')\n",
    "    plt.show()\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "# X contains all columns except 'type', which is our target variable\n",
    "# y contains only the 'type' column which has been encoded to numeric values\n",
    "X = df.drop('type', axis=1)\n",
    "y = df['type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to the training data, to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71160486",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-20T17:43:42.542581Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# This code block is foor all the individual baseline models\n",
    "model_results = {}\n",
    "\n",
    "# Add this helper function for plotting confusion matrices\n",
    "def plot_confusion_matrix(y_true, y_pred, title, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {title}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to get weighted avg f1-score from classification report\n",
    "def get_weighted_f1(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
    "    return report['weighted avg']['f1-score']\n",
    "\n",
    "# Initialize XGBoost classifier with specific parameters\n",
    "# use_label_encoder=False: Avoid using the deprecated label encoder\n",
    "# eval_metric='mlogloss': Use multiclass log loss as evaluation metric\n",
    "# verbosity=0: Suppress verbose output\n",
    "# random_state=42: Set seed for reproducibility\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', verbosity=0, random_state=42)\n",
    "\n",
    "# Train the XGBoost model on the training data\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Use the original class names from the label encoder for better readability in the report\n",
    "model_results['XGBoost'] = {'report': classification_report(y_test, y_pred_xgb, target_names=label_encoder.classes_),\n",
    "                           'weighted_f1': get_weighted_f1(y_test, y_pred_xgb)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_xgb, 'XGBoost', label_encoder.classes_)\n",
    "\n",
    "# Initialize Random Forest classifier with specific parameters\n",
    "# n_estimators=25: Use 25 trees in the forest\n",
    "# random_state=42: Set seed for reproducibility\n",
    "rf_model = RandomForestClassifier(n_estimators=25, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Random Forest model on the training data\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the classification report\n",
    "model_results['Random Forest'] = {'report': classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_),\n",
    "                                  'weighted_f1': get_weighted_f1(y_test, y_pred_rf)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_rf, 'Random Forest', label_encoder.classes_)\n",
    "# Initialize the SVM classifier with RBF kernel for non-linear data\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# Train the SVM model on the resampled training data\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_results['SVM'] = {'report': classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_),\n",
    "                        'weighted_f1': get_weighted_f1(y_test, y_pred_svm)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM', label_encoder.classes_)\n",
    "\n",
    "# Now, a SVM classifier with linear kernel\n",
    "svm_linear_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Train the SVM model on the resampled training data\n",
    "svm_linear_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm_linear = svm_linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_results['SVM Linear'] = {'report': classification_report(y_test, y_pred_svm_linear, target_names=label_encoder.classes_),\n",
    "                               'weighted_f1': get_weighted_f1(y_test, y_pred_svm_linear)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_svm_linear, 'SVM Linear', label_encoder.classes_)\n",
    "#Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the Logistic Regression model on the resampled training data\n",
    "logistic_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_logistic = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_results['Logistic Regression'] = {'report': classification_report(y_test, y_pred_logistic, target_names=label_encoder.classes_),\n",
    "                                        'weighted_f1': get_weighted_f1(y_test, y_pred_logistic)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_logistic, 'Logistic Regression', label_encoder.classes_)\n",
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the KNN model on the resampled training data\n",
    "knn_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "model_results['KNN'] = {'report': classification_report(y_test, y_pred_knn, target_names=label_encoder.classes_),\n",
    "                        'weighted_f1': get_weighted_f1(y_test, y_pred_knn)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN', label_encoder.classes_)\n",
    "\n",
    "# Sort the model results by weighted f1-score\n",
    "sorted_model_results = sorted(model_results.items(), key=lambda x: x[1]['weighted_f1'], reverse=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Model Results sorted by weighted f1-score:\")\n",
    "for model, result in sorted_model_results:\n",
    "    print(f\"\\n{model} Results:\")\n",
    "    print(result['report'])\n",
    "    print(f\"Weighted F1-Score: {result['weighted_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b44c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:43:13.143289Z",
     "start_time": "2025-04-20T17:40:40.708048Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "ensemble_results = {}\n",
    "\n",
    "# we are using the best 3 models to create an ensemble model, which is XGBoost, Random Forest, and KNN\n",
    "# This code block is for all the ensemble models\n",
    "# Create a VotingClassifier\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model),\n",
    "        ('knn', knn_model)\n",
    "    ],\n",
    "    voting='hard'  # 'hard' for majority voting, 'soft' for averaging probabilities\n",
    ")\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_results['Voting Classifier'] = {'report': classification_report(y_test, y_pred_voting, target_names=label_encoder.classes_),\n",
    "                                        'weighted_f1': get_weighted_f1(y_test, y_pred_voting)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_voting, 'Voting Classifier', label_encoder.classes_)\n",
    "\n",
    "# Soft Voting results\n",
    "soft_voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model),\n",
    "        ('knn', knn_model)\n",
    "    ],  \n",
    "    voting='soft'  # 'hard' for majority voting, 'soft' for averaging probabilities\n",
    ")\n",
    "\n",
    "# Train the soft voting model\n",
    "soft_voting_model.fit(X_train_resampled, y_train_resampled) \n",
    "\n",
    "# Make predictions\n",
    "y_pred_soft_voting = soft_voting_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the soft voting model\n",
    "ensemble_results['Soft Voting'] = {'report': classification_report(y_test, y_pred_soft_voting, target_names=label_encoder.classes_),\n",
    "                                  'weighted_f1': get_weighted_f1(y_test, y_pred_soft_voting)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_soft_voting, 'Soft Voting', label_encoder.classes_)\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model),   \n",
    "        ('knn', knn_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(random_state=42, max_iter=1000)\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)   \n",
    "\n",
    "# Make predictions\n",
    "y_pred_stacking = stacking_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "ensemble_results['Stacking Classifier'] = {'report': classification_report(y_test, y_pred_stacking, target_names=label_encoder.classes_),\n",
    "                                         'weighted_f1': get_weighted_f1(y_test, y_pred_stacking)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_stacking, 'Stacking Classifier', label_encoder.classes_)\n",
    "\n",
    "# Bagging Classifier\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")   \n",
    "\n",
    "# Train the bagging model\n",
    "bagging_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bagging = bagging_model.predict(X_test_scaled)   \n",
    "\n",
    "# Evaluate the bagging model\n",
    "ensemble_results['Bagging Classifier'] = {'report': classification_report(y_test, y_pred_bagging, target_names=label_encoder.classes_),\n",
    "                                         'weighted_f1': get_weighted_f1(y_test, y_pred_bagging)}        \n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_bagging, 'Bagging Classifier', label_encoder.classes_)\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")           \n",
    "\n",
    "# Train the AdaBoost model\n",
    "ada_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ada = ada_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the AdaBoost model\n",
    "ensemble_results['AdaBoost Classifier'] = {'report': classification_report(y_test, y_pred_ada, target_names=label_encoder.classes_),\n",
    "                                          'weighted_f1': get_weighted_f1(y_test, y_pred_ada)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_ada, 'AdaBoost Classifier', label_encoder.classes_)\n",
    "\n",
    "# Fine-tune parameters\n",
    "gradient_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,  # Add randomness\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the GradientBoosting model\n",
    "gradient_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gradient = gradient_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the GradientBoosting model\n",
    "ensemble_results['GradientBoosting Classifier'] = {'report': classification_report(y_test, y_pred_gradient, target_names=label_encoder.classes_),\n",
    "                                                  'weighted_f1': get_weighted_f1(y_test, y_pred_gradient)}\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_gradient, 'GradientBoosting Classifier', label_encoder.classes_)\n",
    "\n",
    "# Print the results\n",
    "sorted_ensemble_results = sorted(ensemble_results.items(), key=lambda x: x[1]['weighted_f1'], reverse=True)\n",
    "print(\"Ensemble Model Results sorted by weighted f1-score:\")\n",
    "for model, result in sorted_ensemble_results:\n",
    "    print(f\"\\n{model} Results:\")\n",
    "    print(result['report'])\n",
    "    print(f\"Weighted F1-Score: {result['weighted_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "348cfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def initialize_df():\n",
    "    try:\n",
    "        # Define the path to the CSV file\n",
    "        df = pd.read_csv(full_path)\n",
    "        if 'record' in df.columns:\n",
    "            df = df.drop(columns=['record'])\n",
    "        df = df[df['type'] != 'Q']\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['type'] = label_encoder.fit_transform(df['type'])\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file 'MIT-BIH Arrhythmia Database.csv' was not found.\")\n",
    "        print(\"Please ensure the file exists in the current directory.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def initialize_data(df):\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    X = df.drop(columns=['type'])\n",
    "    y = df['type']\n",
    "    return X, y\n",
    "\n",
    "def clean_data(X, y):\n",
    "    if X is None or y is None:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform both training and test data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Apply SMOTE to the training data, to balance the classes\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    return X_train_resampled, y_train_resampled, X_test_scaled, y_test\n",
    "\n",
    "def get_accuracy(y_pred, y_test):\n",
    "    if y_pred is None or y_test is None:\n",
    "        return 0\n",
    "    \n",
    "    import numpy as np\n",
    "    accuracy = 1 - np.sum(np.abs(y_pred - y_test)) / np.shape(y_pred)[0]\n",
    "    return accuracy\n",
    "\n",
    "def test_prediction(df):\n",
    "    if df is None:\n",
    "        print(\"Error: DataFrame is None. Cannot proceed with prediction.\")\n",
    "        return 0\n",
    "    \n",
    "    #Create Weak Learner\n",
    "    rf_model = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "    X, y = initialize_data(df)\n",
    "    if X is None or y is None:\n",
    "        return 0\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = clean_data(X, y)\n",
    "    if X_train is None:\n",
    "        return 0\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    return get_accuracy(y_pred, y_test)\n",
    "\n",
    "def print_statistics(y_pred, y_test):\n",
    "    if y_pred is None or y_test is None:\n",
    "        print(\"Error: Cannot print statistics with None values.\")\n",
    "        return\n",
    "    \n",
    "    #Visualize the Confusion Matrix\n",
    "    print(\"The Confusion Matrix of the Model is:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    #Calculate the Accuracy\n",
    "    accuracy = get_accuracy(y_pred, y_test)\n",
    "    print(\"The Accuracy of the Model is:\", accuracy, \"/ 1.0\")\n",
    "    #Calculate the Precision, Recall, and F1 Score\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    prf = precision_recall_fscore_support(y_pred, y_test, average='weighted')\n",
    "    print(\"The Precision of the Model is:\", prf[0], \"/ 1.0\")\n",
    "    print(\"The Recall of the Model is:\", prf[1], \"/ 1.0\")\n",
    "    print(\"The F1 Score is:\", prf[2])\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c66638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Method: Calculate Pearson Coefficient\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = initialize_df()\n",
    "res = list()\n",
    "for c in df.columns:\n",
    "    res.append((c, stats.pearsonr(df[c], df[\"type\"]).statistic))\n",
    "\n",
    "#Drop Uncorrelated Features\n",
    "print(\"Uncorrelated Features:\")\n",
    "for p in res:\n",
    "    r = p[1]\n",
    "    if np.abs(r) < 0.1: #All features have a coefficient < 0.5, so we lower the minimum to remove them to < 0.1\n",
    "        print(p[0], p[1])\n",
    "        df = df.drop(columns=[p[0]])\n",
    "\n",
    "#Find Accuracy\n",
    "y_pred_filter = test_prediction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e622926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper Method: Start with Full Set of Features & Begin Removing Features Based on which increases accuracy the mos\n",
    "\n",
    "df = initialize_df()\n",
    "cond = True\n",
    "while cond == True:\n",
    "    curr = 'type'\n",
    "    wrap_accuracy = test_prediction(df)\n",
    "    print(\"Initial Performance:\", wrap_accuracy)\n",
    "    max_ = wrap_accuracy\n",
    "    for c in df.drop(columns=['type']).columns:\n",
    "        pred = test_prediction(df.drop(columns=[c]))\n",
    "        print(\"Remove\", c, \"Performance\", pred)\n",
    "        if pred > max_:\n",
    "            curr = c\n",
    "            max_ = pred\n",
    "    #max = y_pred_wrap\n",
    "    #for i in range(len(predictions)):\n",
    "        #if predictions[i][\n",
    "    if curr == 'type':\n",
    "        print(\"Current Set Best Performance\")\n",
    "        cond = False\n",
    "    else:\n",
    "        print(\"Dropped Feature:\", curr)\n",
    "        df = df.drop(columns=[curr])\n",
    "\n",
    "#Find Accuracy\n",
    "y_pred_wrap = test_prediction(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
